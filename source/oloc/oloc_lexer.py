r"""
:author: WaterRun
:date: 2025-03-30
:file: oloc_lexer.py
:description: Oloc lexer
"""

import time
import oloc_utils as utils
from oloc_evaluator import Evaluator
from oloc_exceptions import *
from oloc_token import Token


class Lexer:
    r"""
    è¯æ³•åˆ†æå™¨
    :param expression: å¾…å¤„ç†çš„è¡¨è¾¾å¼
    """

    def __init__(self, expression: str):
        self.expression = expression
        self.tokens: list[Token] = []
        self.time_cost = -1

    def _convert_token_flow(self) -> None:
        r"""
        å°†è¡¨è¾¾å¼è½¬ä¸ºTokenæµ,å¹¶æ£€æŸ¥Tokençš„åˆæ³•æ€§
        :return: None
        """
        self.tokens = Lexer.tokenizer(self.expression)
        self._self_check()


    def _self_check(self) -> None:
        r"""
        Tokenæµè‡ªæ£€
        :raise OlocInvalidTokenException: å¦‚æœTokenä¸åˆæ³•
        :return: None
        """
        for check_token in self.tokens:
            if not check_token.is_legal:
                raise OlocInvalidTokenException(
                    exception_type=check_token.get_exception_type(),
                    expression=self.expression,
                    positions=list(range(*[check_token.range[0], check_token.range[1]])),
                    token_content=check_token.value if check_token else "",
                )
            if check_token.type == Token.TYPE.LONG_CUSTOM and check_token.value.startswith('<__reserved'):
                raise OlocReservedWordException(
                    exception_type=OlocReservedWordException.EXCEPTION_TYPE.IS_RESERVED,
                    expression=self.expression,
                    positions=list(range(*[check_token.range[0], check_token.range[1]])),
                    conflict_str=check_token.value,
                )

    def _formal_complementation(self) -> None:
        r"""
        è¡¥å…¨è¡¨è¾¾å¼ä¸­çš„ä¸€äº›ç‰¹æ®Šå½¢å¼,å¦‚è¢«çœç•¥çš„ä¹˜å·
        :return: None
        """

        NUMBERS = {
            Token.TYPE.FINITE_DECIMAL,
            Token.TYPE.INFINITE_DECIMAL,
            Token.TYPE.PERCENTAGE,
            Token.TYPE.INTEGER,
            Token.TYPE.NATIVE_IRRATIONAL,
            Token.TYPE.SHORT_CUSTOM,
            Token.TYPE.LONG_CUSTOM
        }

        IRRATIONALS = {
            Token.TYPE.LONG_CUSTOM,
            Token.TYPE.SHORT_CUSTOM,
            Token.TYPE.NATIVE_IRRATIONAL
        }

        def _add_multiply(add_index: int):
            r"""
            æ·»åŠ ä¹˜å·è‡³ Token æµ
            :param add_index: è¦æ·»åŠ ä¹˜å·çš„ä½ç½®
            """
            self.tokens = (
                    self.tokens[:add_index + 1]
                    + [Token(Token.TYPE.OPERATOR, "*", [add_index + 1, add_index + 2])]
                    + self.tokens[add_index + 1:]
            )

        token_index = 0
        while token_index < len(self.tokens) - 1:
            current_token = self.tokens[token_index]
            next_token = self.tokens[token_index + 1]

            conditions = [
                # æƒ…å†µ 1: æ•°å­—åæ¥ (
                (lambda t1, t2: t1 in NUMBERS and t2 == Token.TYPE.LBRACKET),

                # æƒ…å†µ 2: æ— ç†æ•°å‚æ•°åæ¥ (
                (lambda t1, t2: t1 == Token.TYPE.IRRATIONAL_PARAM and t2 == Token.TYPE.LBRACKET),

                # æƒ…å†µ 3: ) åæ¥æ•°å­—
                (lambda t1, t2: t1 == Token.TYPE.RBRACKET and t2 in NUMBERS),

                # æƒ…å†µ 4: æ— ç†æ•°åæ¥æ— ç†æ•°
                (lambda t1, t2: t1 in IRRATIONALS and t2 in IRRATIONALS),

                # æƒ…å†µ 5: æ•°å­—åæ¥æ— ç†æ•°
                (lambda t1, t2: t1 in NUMBERS and t2 in IRRATIONALS),

                # æƒ…å†µ 6: æ— ç†æ•°åæ¥æ•°å­—
                (lambda t1, t2: t1 in IRRATIONALS and t2 in NUMBERS),

                # æƒ…å†µ 7: æ•°å­—åæ¥å‡½æ•°å
                (lambda t1, t2: t1 in NUMBERS and t2 == Token.TYPE.FUNCTION)
            ]

            if any(condition(current_token.type, next_token.type) for condition in conditions):
                _add_multiply(token_index)

            token_index += 1
            self.tokens, self.expression = Lexer.update(self.tokens)

    def _check_denominator(self, check_tokens: list[Token, Token, Token]) -> list[Token, Token, Token]:
        r"""
        æ£€æŸ¥ä¼ å…¥çš„åˆ†æ•°æµ(åˆ†å­,åˆ†æ•°çº¿,åˆ†æ¯)ä¸­çš„åˆ†æ¯æ˜¯å¦åˆæ³•
        :param check_tokens: è¢«æ£€æŸ¥çš„Token
        :raise OlocInvalidCalculationException: å¦‚æœåˆ†æ¯ä¸º0
        :return: åŸæ ·è¿”å›
        """
        if int(check_tokens[2].value) == 0:
            raise OlocInvalidCalculationException(
                exception_type=OlocInvalidCalculationException.EXCEPTION_TYPE.DIVIDE_BY_ZERO,
                expression=self.expression,
                positions=list(range(*[check_tokens[0].range[0], check_tokens[2].range[1]])),
                computing_unit=check_tokens[0].value + check_tokens[1].value + check_tokens[2].value,
            )
        return check_tokens

    def _fractionalization(self) -> None:
        r"""
        å°†è¡¨è¾¾å¼Tokenæµä¸­çš„å„ç§æ•°å­—è½¬æ¢ä¸ºåˆ†æ•°
        :return: None
        """

        def _add_bracket(to_add: [Token, Token, Token]) -> [Token, Token, Token, Token, Token]:
            r"""
            ä¸ºè½¬æ¢çš„ç»“æœæ·»åŠ æ‹¬å·
            :param to_add: å¾…æ·»åŠ çš„ç»“æœ
            :return: æ·»åŠ åçš„ç»“æœ
            """
            return [Token(Token.TYPE.LBRACKET, "(", [0, 0])] + \
                to_add + [Token(Token.TYPE.RBRACKET, ")", [0, 0])]

        def _convert_finite_decimal(finite_decimal: Token) -> [Token, Token, Token]:
            r"""
            å°†æœ‰é™å°æ•°è½¬ä¸ºåˆ†æ•°
            :param finite_decimal: å¾…è½¬æ¢çš„æœ‰é™å°æ•°
            :return: è½¬æ¢åçš„åˆ†æ•°Tokenæµ(åˆ†å­,åˆ†æ•°çº¿,åˆ†æ¯)
            """
            integer_part, decimal_part = finite_decimal.value.split('.')

            numerator = int(integer_part + decimal_part)
            denominator = 10 ** len(decimal_part)

            if int(integer_part) < 0:
                numerator = -numerator

            return [Token(Token.TYPE.INTEGER,
                              str(numerator),
                              [finite_decimal.range[0], finite_decimal.range[0] + len(str(numerator))]
                              ),
                        Token(Token.TYPE.OPERATOR,
                              "/",
                              [finite_decimal.range[0] + len(str(numerator)) + 1,
                               finite_decimal.range[0] + len(str(numerator)) + 2]
                              ),
                        Token(Token.TYPE.INTEGER,
                              str(denominator),
                              [finite_decimal.range[0] + len(str(numerator)) + 2,
                               finite_decimal.range[0] + len(str(numerator)) + 2 + len(str(denominator))]
                              ),
                        ]

        def _convert_infinite_decimal(infinite_decimal: Token) -> [Token, Token, Token]:
            r"""
            å°†æ— é™å¾ªç¯å°æ•°è½¬ä¸ºåˆ†æ•°
            :param infinite_decimal: å¾…è½¬æ¢çš„æ— é™å°æ•°
            :return: è½¬æ¢åçš„åˆ†æ•°, ä¾æ¬¡ä¸ºåˆ†å­, åˆ†æ•°çº¿, åˆ†æ¯
            """

            def _spilt_decimal_parts(process_decimal: str) -> list[str, str]:
                r"""
                åˆ‡åˆ†æ— é™å¾ªç¯å°æ•°ä¸­é‡å¤çš„éƒ¨åˆ†å’Œæœ‰é™å°æ•°éƒ¨åˆ†
                :param process_decimal: å¾…æŸ¥æ‰¾çš„æ— é™å¾ªç¯å°æ•°
                :return: ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨, ç¬¬ä¸€é¡¹æ˜¯æŸ¥æ‰¾åˆ°çš„é‡å¤éƒ¨åˆ†, ç¬¬äºŒé¡¹æ˜¯ç§»é™¤é‡å¤éƒ¨åˆ†åçš„æœ‰é™å°æ•°
                """
                # å¤„ç†ç»“å°¾æœ‰ç‚¹å·çš„æƒ…å†µ
                if '.' in process_decimal and process_decimal.count('.') > 1:
                    # ç§»é™¤ç»“å°¾çš„æ‰€æœ‰ç‚¹å·
                    base_number = process_decimal.rstrip('.')

                    # åˆ†ç¦»æ•´æ•°å’Œå°æ•°éƒ¨åˆ†
                    integer_part, decimal_part = base_number.split('.')

                    # æœ€åä¸€ä½æ•°å­—æ˜¯å¾ªç¯éƒ¨åˆ†
                    if decimal_part:
                        repeat_part = decimal_part[-1]
                        finite_part = integer_part + "." + decimal_part[:-1]
                    else:
                        # å¦‚æœæ²¡æœ‰å°æ•°éƒ¨åˆ†ï¼Œé»˜è®¤å¾ªç¯éƒ¨åˆ†ä¸º0
                        repeat_part = "0"
                        finite_part = integer_part + ".0"

                    return [repeat_part, finite_part]

                # å¤„ç†æ˜¾å¼å£°æ˜å¾ªç¯éƒ¨åˆ†çš„æƒ…å†µï¼ˆä½¿ç”¨:åˆ†éš”ï¼‰
                else:
                    base_number, repeat_part = process_decimal.split(':')

                    if '.' in base_number:
                        integer_part, decimal_part = base_number.split('.')
                        finite_part = integer_part + "." + decimal_part
                    else:
                        # å¦‚æœåŸºæ•°éƒ¨åˆ†æ²¡æœ‰å°æ•°ç‚¹ï¼ŒåŠ ä¸Š.0
                        finite_part = base_number + ".0"

                    return [repeat_part, finite_part]

            def _fraction_from_parts(repeat_part: str, finite_part: str) -> list[Token, Token, Token]:
                r"""
                æ ¹æ®å¾ªç¯éƒ¨åˆ†å’Œæœ‰é™éƒ¨åˆ†è®¡ç®—åˆ†æ•°å½¢å¼
                :param repeat_part: å¾ªç¯éƒ¨åˆ†
                :param finite_part: æœ‰é™éƒ¨åˆ†
                :return: è½¬æ¢åçš„åˆ†æ•°Tokenæµ(åˆ†å­,åˆ†æ•°çº¿,åˆ†æ¯)
                """
                # åˆ†è§£æœ‰é™éƒ¨åˆ†
                if '.' in finite_part:
                    integer_str, decimal_str = finite_part.split('.')
                else:
                    integer_str, decimal_str = finite_part, '0'

                # å°†æ•´æ•°éƒ¨åˆ†è½¬ä¸ºæ•´æ•°
                integer_value = int(integer_str) if integer_str else 0

                # è®¡ç®—åˆ†æ¯ï¼šå¾ªç¯éƒ¨åˆ†äº§ç”Ÿçš„åˆ†æ¯æ˜¯9çš„ä¹˜ç§¯
                denominator = int('9' * len(repeat_part))

                # å¦‚æœæœ‰é™å°æ•°éƒ¨åˆ†éç©ºï¼Œéœ€è¦å°†å¾ªç¯éƒ¨åˆ†ä¹˜ä»¥é€‚å½“çš„å› å­
                if decimal_str:
                    denominator = denominator * (10 ** len(decimal_str))

                # è®¡ç®—åˆ†å­
                numerator = 0

                # å¤„ç†æ•´æ•°éƒ¨åˆ†
                if integer_value:
                    numerator += integer_value * denominator

                # å¤„ç†æœ‰é™å°æ•°éƒ¨åˆ†
                if decimal_str:
                    numerator += int(decimal_str) * int('9' * len(repeat_part))

                # å¤„ç†å¾ªç¯éƒ¨åˆ†
                if repeat_part:
                    numerator += int(repeat_part)

                # è¿”å›åˆ†æ•°å½¢å¼
                return [Token(Token.TYPE.INTEGER,
                                  str(numerator),
                                  [infinite_decimal.range[0], infinite_decimal.range[0] + len(str(numerator))]
                                  ),
                            Token(Token.TYPE.OPERATOR,
                                  "/",
                                  [infinite_decimal.range[0] + len(str(numerator)) + 1,
                                   infinite_decimal.range[0] + len(str(numerator)) + 2]
                                  ),
                            Token(Token.TYPE.INTEGER,
                                  str(denominator),
                                  [infinite_decimal.range[0] + len(str(numerator)) + 2,
                                   infinite_decimal.range[0] + len(str(numerator)) + 2 + len(str(denominator))]
                                  ),
                            ]

            # ä¸»å‡½æ•°é€»è¾‘
            infinite_decimal_str = infinite_decimal.value
            parts = _spilt_decimal_parts(infinite_decimal_str)
            repeat_part, finite_part = parts[0], parts[1]

            # è®¡ç®—åˆ†æ•°
            fraction = _fraction_from_parts(repeat_part, finite_part)

            # è°ƒç”¨åŒ–ç®€å‡½æ•°
            return fraction

        def _convert_percentage(percentage: Token) -> [Token, Token, Token]:
            r"""
            å°†ç™¾åˆ†æ•°è½¬ä¸ºå°æ•°
            :param percentage: å¾…è½¬æ¢çš„ç™¾åˆ†æ•°
            :return: è½¬æ¢åçš„å°æ•°å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚"0.125"
            """
            # å»æ‰ç™¾åˆ†å·
            percentage_str = percentage.value
            percentage_str = percentage_str[:-1]

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å°æ•°ç‚¹ï¼Œç¡®ä¿åˆ†å‰²æ“ä½œä¸ä¼šå‡ºé”™
            if '.' not in percentage_str:
                percentage_str += '.0'

            integer_part, decimal_part = percentage_str.split('.')

            # æ ¹æ®æ•´æ•°éƒ¨åˆ†é•¿åº¦è°ƒæ•´å°æ•°ç‚¹ä½ç½®
            if integer_part == '0':
                percentage_str = '0.00' + decimal_part
            elif len(integer_part) == 1:
                percentage_str = '0.0' + integer_part + decimal_part
            elif len(integer_part) == 2:
                percentage_str = '0.' + integer_part + decimal_part
            else:
                decimal_point_pos = len(integer_part) - 2
                percentage_str = integer_part[:decimal_point_pos] + '.' + integer_part[
                                                                          decimal_point_pos:] + decimal_part

            percentage_str = percentage_str.rstrip('0')
            if percentage_str.endswith('.'):
                percentage_str = percentage_str[:-1]

            return [Token(Token.TYPE.INTEGER, percentage_str,
                          [percentage.range[0], percentage.range[0] + len(percentage_str)]),
                    Token(Token.TYPE.OPERATOR, "/",
                          [percentage.range[0] + len(percentage_str), percentage.range[0] + len(percentage_str) + 1]),
                    Token(Token.TYPE.INTEGER, "1",
                          [percentage.range[0] + len(percentage_str) + 1,
                           percentage.range[0] + len(percentage_str) + 2]),
                    ] if '.' not in percentage_str else _convert_finite_decimal(
                Token(Token.TYPE.FINITE_DECIMAL, percentage_str,
                      [percentage.range[0], percentage.range[0] + len(percentage_str)]))

        fractionalized_tokens = []

        convert_num_types = [
            Token.TYPE.PERCENTAGE,
            Token.TYPE.FINITE_DECIMAL,
            Token.TYPE.INFINITE_DECIMAL,
        ]

        tokens_to_fractionalized: list[Token] = []
        token_index = 0
        while token_index < len(self.tokens):
            temp_token = self.tokens[token_index]
            if (convert_type := temp_token.type) == Token.TYPE.INTEGER and \
                    token_index + 2 < len(self.tokens) and \
                    self.tokens[token_index + 1].value == "/" and \
                    self.tokens[token_index + 2].type == Token.TYPE.INTEGER:
                fractionalized_tokens += Evaluator.simplify(
                    self._check_denominator([temp_token, self.tokens[token_index + 1], self.tokens[token_index + 2]]))
                token_index += 2
            elif convert_type in convert_num_types:
                match convert_type:
                    case Token.TYPE.FINITE_DECIMAL:
                        tokens_to_fractionalized = self._check_denominator(_convert_finite_decimal(temp_token))
                    case Token.TYPE.INFINITE_DECIMAL:
                        tokens_to_fractionalized = self._check_denominator(_convert_infinite_decimal(temp_token))
                    case Token.TYPE.PERCENTAGE:
                        tokens_to_fractionalized = self._check_denominator(_convert_percentage(temp_token))
                fractionalized_tokens += _add_bracket(Evaluator.simplify(tokens_to_fractionalized))
            else:
                fractionalized_tokens += [temp_token]
            token_index += 1

        self.tokens, self.expression = Lexer.update(fractionalized_tokens)

    def _bracket_checking_harmonisation(self) -> None:
        """
        æ‹¬å·æ£€æŸ¥ä¸ç»Ÿä¸€åŒ–
        :raise OlocInvalidBracketException: å¦‚æœæ‹¬å·å‡ºç°å±‚çº§é”™è¯¯æˆ–ä¸åŒ¹é…
        :return: None
        """
        BRACKET_PRIORITY = {'(': 1, '[': 2, '{': 3, ')': 1, ']': 2, '}': 3}
        BRACKET_MATCH = {'(': ')', '[': ']', '{': '}', ')': '(', ']': '[', '}': '{'}

        stack = []

        for temp_token in self.tokens:
            if temp_token.type == Token.TYPE.LBRACKET:
                if stack and BRACKET_PRIORITY[temp_token.value] > BRACKET_PRIORITY[stack[-1][0]]:
                    raise OlocInvalidBracketException(
                        exception_type=OlocInvalidBracketException.EXCEPTION_TYPE.INCORRECT_BRACKET_HIERARCHY,
                        expression=self.expression,
                        positions=[temp_token.range[0]],
                        err_bracket=temp_token.value
                    )
                stack.append((temp_token.value, temp_token.range[0], BRACKET_PRIORITY[temp_token.value]))

            elif temp_token.type == Token.TYPE.RBRACKET:
                if not stack:
                    raise OlocInvalidBracketException(
                        exception_type=OlocInvalidBracketException.EXCEPTION_TYPE.MISMATCH_RIGHT_BRACKET,
                        expression=self.expression,
                        positions=[temp_token.range[0]],
                        err_bracket=temp_token.value
                    )

                last_left_bracket, last_position, last_priority = stack.pop()

                if BRACKET_MATCH[last_left_bracket] != temp_token.value:
                    raise OlocInvalidBracketException(
                        exception_type=OlocInvalidBracketException.EXCEPTION_TYPE.MISMATCH_LEFT_BRACKET,
                        expression=self.expression,
                        positions=[last_position],
                        err_bracket=last_left_bracket
                    )

                if BRACKET_PRIORITY[last_left_bracket] != BRACKET_PRIORITY[temp_token.value]:
                    raise OlocInvalidBracketException(
                        exception_type=OlocInvalidBracketException.EXCEPTION_TYPE.INCORRECT_BRACKET_HIERARCHY,
                        expression=self.expression,
                        positions=[last_position],
                        err_bracket=last_left_bracket
                    )

        if stack:
            last_left_bracket, last_position, _ = stack.pop()
            raise OlocInvalidBracketException(
                exception_type=OlocInvalidBracketException.EXCEPTION_TYPE.MISMATCH_LEFT_BRACKET,
                expression=self.expression,
                positions=[last_position],
                err_bracket=last_left_bracket
            )

        for bracket_token in self.tokens:
            if bracket_token.type == Token.TYPE.LBRACKET:
                bracket_token.value = '('
            elif bracket_token.type == Token.TYPE.RBRACKET:
                bracket_token.value = ')'

        self.tokens, self.expression = Lexer.update(self.tokens)

    def _static_check(self):
        r"""
        é™æ€æ£€æŸ¥,ç¡®ä¿åœ¨è¿›å…¥è¯­æ³•åˆ†æå‰è¯­å¥çš„åˆæ³•æ€§
        :raise OlocInvalidTokenException: å½“å­˜åœ¨éæ³•çš„è¿ç®—ç¬¦,æ‹¬å·æˆ–å‡½æ•°æ—¶,æˆ–ç±»å‹é”™è¯¯æ—¶
        :raise OlocIrrationalNumberFormatException: å½“å­˜åœ¨éæ³•çš„æ— ç†æ•°å‚æ•°æ—¶
        :return: None
        """
        valid_operators = ('+', '-', '*', '/', 'âˆš', 'Â°', '^', '%', '!', '|')
        valid_bracket = ('(', ')')
        valid_function = tuple(utils.get_function_mapping_table().keys())
        valid_types = (
            Token.TYPE.INTEGER,
            Token.TYPE.OPERATOR,
            Token.TYPE.RBRACKET,
            Token.TYPE.LBRACKET,
            Token.TYPE.LONG_CUSTOM,
            Token.TYPE.SHORT_CUSTOM,
            Token.TYPE.NATIVE_IRRATIONAL,
            Token.TYPE.IRRATIONAL_PARAM,
            Token.TYPE.FUNCTION,
            Token.TYPE.PARAM_SEPARATOR,
        )
        valid_numbers = (
            Token.TYPE.INTEGER,
            Token.TYPE.LONG_CUSTOM,
            Token.TYPE.SHORT_CUSTOM,
            Token.TYPE.NATIVE_IRRATIONAL,
        )

        self.token, self.expression = Lexer.update(self.tokens)
        self._self_check()

        absolute_symbol_waiting_right = False
        absolute_symbol_current_index = -1

        for token_index, temp_token in enumerate(self.tokens):

            # ç±»å‹æ£€æŸ¥
            if temp_token.type not in valid_types:
                raise OlocStaticCheckException(
                    exception_type=OlocStaticCheckException.EXCEPTION_TYPE.INVALID_TYPES,
                    expression=self.expression,
                    positions=list(range(*temp_token.range)),
                    token_content=temp_token.type,
                )

            # è¿ç®—ç¬¦æ£€æŸ¥
            if temp_token.type == Token.TYPE.OPERATOR:

                def operator_front_legal(index: int) -> bool:
                    r"""
                    æ‰¾å‡ºè¿ç®—ç¬¦ä¹‹å‰å†…å®¹æ˜¯å¦åˆæ³•
                    :param index: è¿ç®—ç¬¦çš„ä¸‹æ ‡
                    :return: æ˜¯å¦åˆæ³•
                    """

                def operator_rear_legal(index: int) -> bool:
                    r"""
                    æ‰¾å‡ºè¿ç®—ç¬¦ä¹‹åå†…å®¹æ˜¯å¦åˆæ³•
                    :param index: è¿ç®—ç¬¦çš„ä¸‹æ ‡
                    :return: æ˜¯å¦åˆæ³•
                    """

                match temp_token.value:
                    case ".":
                        raise OlocStaticCheckException(
                            exception_type=OlocStaticCheckException.EXCEPTION_TYPE.OPERATOR_DOT,
                            expression=self.expression,
                            positions=list(range(*temp_token.range)),
                            token_content=temp_token.value,
                        )

                    case "|":

                        absolute_symbol_waiting_right = not absolute_symbol_waiting_right
                        absolute_symbol_current_index = token_index
                        if absolute_symbol_waiting_right:
                            if not operator_front_legal(token_index):
                                ...
                        else:
                            if not operator_rear_legal(token_index):
                                ...

                    case "âˆš" | "+" | "-":

                        if not operator_rear_legal(token_index):
                            ...

                    case "!" | "Â°":

                        if not operator_front_legal(token_index):
                            ...

                    case  "*" | "/" | "^" | "%":
                        ... # todo

                if temp_token.value not in valid_operators:
                    raise OlocStaticCheckException(
                        exception_type=OlocStaticCheckException.EXCEPTION_TYPE.INVALID_OPERATOR,
                        expression=self.expression,
                        positions=list(range(*temp_token.range)),
                        token_content=temp_token.value,
                    )

            # å‡½æ•°æ£€æŸ¥
            if temp_token.type == Token.TYPE.FUNCTION:

                if temp_token.value not in valid_function:
                    raise OlocStaticCheckException(
                        exception_type=OlocStaticCheckException.EXCEPTION_TYPE.FUNCTION_NAME,
                        expression=self.expression,
                        positions=list(range(*temp_token.range)),
                        token_content=temp_token.value,
                    )

                if token_index + 1 == len(self.tokens) or self.tokens[token_index + 1].type != Token.TYPE.LBRACKET:
                    raise OlocStaticCheckException(
                        exception_type=OlocStaticCheckException.EXCEPTION_TYPE.FUNCTION_PLACE,
                        expression=self.expression,
                        positions=list(range(*temp_token.range)),
                        token_content=temp_token.value,
                    )

            # å‡½æ•°åˆ†éš”ç¬¦æ£€æŸ¥
            if temp_token.type == Token.TYPE.PARAM_SEPARATOR:
                ...

            # æ‹¬å·æ£€æŸ¥
            if temp_token.type in (Token.TYPE.LBRACKET, Token.TYPE.RBRACKET):

                if temp_token.value not in valid_bracket:
                    raise OlocStaticCheckException(
                        exception_type=OlocStaticCheckException.EXCEPTION_TYPE.INVALID_BRACKET,
                        expression=self.expression,
                        positions=list(range(*temp_token.range)),
                        token_content=temp_token.value,
                    )

            # æ— ç†æ•°å‚æ•°æ£€æŸ¥
            if temp_token.type == Token.TYPE.IRRATIONAL_PARAM:

                if len(self.tokens) == 0 or self.tokens[token_index - 1].type not in [
                    Token.TYPE.NATIVE_IRRATIONAL,
                    Token.TYPE.SHORT_CUSTOM,
                    Token.TYPE.LONG_CUSTOM,
                    Token.TYPE.RBRACKET,
                    Token.TYPE.INTEGER
                ]:
                    raise OlocStaticCheckException(
                        exception_type=OlocStaticCheckException.EXCEPTION_TYPE.INVALID_IRRPARAM,
                        expression=self.expression,
                        positions=list(range(*temp_token.range)),
                        token_content=temp_token.value,
                    )

        if absolute_symbol_waiting_right:
            raise OlocStaticCheckException(
                exception_type=OlocStaticCheckException.EXCEPTION_TYPE.MISMATCHED_ABSOLUTE,
                expression=self.expression,
                positions=[absolute_symbol_current_index],
                token_content="|",
            )

    def execute(self):
        r"""
        æ‰§è¡Œåˆ†è¯å™¨
        :return: None
        """

        start_time = time.time_ns()
        self._convert_token_flow()
        self._formal_complementation()
        self._fractionalization()
        self._bracket_checking_harmonisation()
        self._static_check()
        self.time_cost = time.time_ns() - start_time

    """
    é™æ€æ–¹æ³•
    """

    @staticmethod
    def tokenizer(expression: str) -> list[Token]:
        r"""
        åˆ†è¯å™¨
        :param expression: å¾…åˆ†è¯çš„è¡¨è¾¾å¼
        :raise OlocIrrationalNumberFormatException: å¦‚æœæ— ç†æ•°å½¢å¼ä¸åˆæ³•
        :return: åˆ†è¯åçš„Tokenåˆ—è¡¨
        """
        function_names = utils.get_function_name_list()
        symbol_mapping_table = utils.get_symbol_mapping_table()

        mark_list = [Token.TYPE.UNKNOWN for _ in range(len(expression))]

        """
        æ¨¡å—æ ‡è®°
        """

        # æ ‡è®°è‡ªå®šä¹‰é•¿æ— ç†æ•°
        for index, char in enumerate(expression):
            # å·²ç»æ ‡è®°è¿‡çš„è·³è¿‡

            if index > 0 and mark_list[index - 1] == Token.TYPE.LONG_CUSTOM:
                continue

            if char == '<':

                # å•ä¸ªå·¦å°–æ‹¬å·æ˜¯é”™è¯¯çš„
                if index == len(expression) - 1:
                    raise OlocIrrationalNumberFormatException(
                        exception_type=OlocIrrationalNumberFormatException.EXCEPTION_TYPE.MISMATCH_LONG_LEFT_SIGN,
                        expression=expression,
                        positions=[index, index],
                    )

                # æŸ¥æ‰¾åŒ¹é…çš„å³å°–æ‹¬å·
                right_bracket_index = None
                for i in range(index + 1, len(expression)):
                    if expression[i] == '>':
                        right_bracket_index = i
                        break

                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„å³å°–æ‹¬å·ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if right_bracket_index is None:
                    raise OlocIrrationalNumberFormatException(
                        exception_type=OlocIrrationalNumberFormatException.EXCEPTION_TYPE.MISMATCH_LONG_LEFT_SIGN,
                        expression=expression,
                        positions=[index, index],
                    )

                # æ ‡è®°æ•´ä¸ªèŒƒå›´ä¸ºLONG_CUSTOM
                for i in range(index, right_bracket_index + 1):
                    mark_list[i] = Token.TYPE.LONG_CUSTOM

        # æ ‡è®°æ— ç†æ•°å‚æ•°
        for index, char in enumerate(expression):

            if mark_list[index] != Token.TYPE.UNKNOWN:
                continue

            if char == "?":
                # è®°å½•å½“å‰ ? çš„ç´¢å¼•å¹¶åˆå§‹åŒ–ç´¢å¼•åˆ—è¡¨
                irrational_param_index_list = [index]

                # å¼€å§‹å‘å‰æ‰«æ
                find_dot = False

                for scan_index in range(index - 1, -1, -1):  # ä»å½“å‰ç´¢å¼•å‘å‰éå†
                    scan_char = expression[scan_index]

                    if mark_list[scan_index] != Token.TYPE.UNKNOWN:
                        break

                    if scan_char.isdigit() or scan_char in {".", "+", "-"}:
                        irrational_param_index_list.append(scan_index)
                        if scan_char == ".":
                            if find_dot:  # å¦‚æœå·²ç»é‡åˆ°è¿‡å°æ•°ç‚¹ï¼Œåœæ­¢æ‰«æ
                                break
                            find_dot = True
                        elif scan_char in {"+", "-"}:  # é‡åˆ°åŠ å·æˆ–å‡å·ï¼Œåœæ­¢æ‰«æ
                            break
                    else:  # éæ•°å­—ã€éç¬¦å·ç›´æ¥åœæ­¢
                        break

                # æ ‡è®°æ‰€æœ‰ç›¸å…³ç´¢å¼•ä¸º IRRATIONAL_PARAM
                for irrational_index in irrational_param_index_list:
                    mark_list[irrational_index] = Token.TYPE.IRRATIONAL_PARAM

        # æ ‡è®°å‡½æ•°
        for func_name in function_names:
            start = 0
            func_len = len(func_name)

            # åœ¨è¡¨è¾¾å¼ä¸­æŸ¥æ‰¾å‡½æ•°å
            while (find_index := expression.find(func_name, start)) != -1:

                end_index = find_index + func_len

                if mark_list[find_index] != Token.TYPE.UNKNOWN:
                    start = end_index
                    continue

                for i in range(find_index, end_index):
                    mark_list[i] = Token.TYPE.FUNCTION

                start = end_index

        # æ ‡è®°æ•°å­—
        for index, char in enumerate(expression):

            # å¦‚æœå½“å‰ç´¢å¼•å·²ç»å¤„ç†è¿‡ï¼Œåˆ™è·³è¿‡
            if mark_list[index] != Token.TYPE.UNKNOWN:
                continue

            # å¤„ç†æ•°å­—
            if char.isdigit():
                mode = Token.TYPE.INTEGER  # é»˜è®¤æ¨¡å¼ä¸ºæ•´æ•°
                attempt_index = index
                digit_index_range_list = [index]  # ä¿å­˜æ•°å­—ç´¢å¼•èŒƒå›´
                find_decimal_point = False  # æ˜¯å¦æ‰¾åˆ°å°æ•°ç‚¹
                is_infinite_decimal = False  # æ˜¯å¦ä¸ºæ— é™å°æ•°

                while attempt_index + 1 < len(expression):
                    attempt_index += 1
                    current_char = expression[attempt_index]

                    if current_char == "%" and mode in [Token.TYPE.INTEGER, Token.TYPE.FINITE_DECIMAL]:
                        if attempt_index + 1 < len(expression) and expression[attempt_index + 1] not in ["+", "-", "*",
                                                                                                         "/",
                                                                                                         "^", "%", "|",
                                                                                                         ")", "]", "}",
                                                                                                         ",", ";"]:
                            break
                        mode = Token.TYPE.PERCENTAGE
                        digit_index_range_list.append(attempt_index)
                        break

                    # å¤„ç†å°æ•°ç‚¹
                    if current_char == ".":
                        if find_decimal_point:  # å¦‚æœå·²ç»æ‰¾åˆ°è¿‡å°æ•°ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæ— é™å°æ•°
                            # æ£€æŸ¥æ˜¯å¦ä¸ºæ— é™å¾ªç¯å°æ•°
                            next_char_index = attempt_index + 1
                            if next_char_index < len(expression) and expression[next_char_index] == ".":
                                is_infinite_decimal = True
                                mode = Token.TYPE.INFINITE_DECIMAL
                                digit_index_range_list.append(attempt_index)  # å°†å½“å‰ç‚¹åŠ å…¥æ ‡æ³¨èŒƒå›´
                                param_index = attempt_index + 1
                                point_count = 1  # è®°å½•è¿ç»­ç‚¹çš„æ•°é‡

                                while param_index < len(expression):
                                    if expression[param_index] == ".":
                                        point_count += 1
                                        digit_index_range_list.append(param_index)  # å°†ç‚¹åŠ å…¥æ ‡æ³¨èŒƒå›´
                                    else:
                                        break  # é‡åˆ°éç‚¹å­—ç¬¦æ—¶é€€å‡º
                                    param_index += 1

                                if not 6 <= point_count <= 3:
                                    break

                                # ç¡®ä¿æœ€åä¸€ä¸ªç‚¹ä¹Ÿè¢«æ ‡è®°
                                attempt_index = param_index - 1
                                continue
                            else:
                                break  # å¦‚æœä¸æ˜¯æ— é™å°æ•°ï¼Œé€€å‡º
                        find_decimal_point = True
                        mode = Token.TYPE.FINITE_DECIMAL
                        digit_index_range_list.append(attempt_index)  # å°†å°æ•°ç‚¹åŠ å…¥æ ‡æ³¨èŒƒå›´
                        continue

                    # å¤„ç†æ˜¾å¼æ ‡æ³¨çš„æ— ç†æ•°
                    if current_char == ":" and find_decimal_point:
                        is_infinite_decimal = True
                        digit_index_range_list.append(attempt_index)
                        next_index = attempt_index + 1
                        while next_index < len(expression):
                            if not expression[next_index].isdigit():
                                break
                            digit_index_range_list.append(next_index)
                            next_index += 1

                    # å¤„ç†æ•°å­—å­—ç¬¦
                    if current_char.isdigit():
                        digit_index_range_list.append(attempt_index)
                    else:
                        break

                # å¦‚æœå½“å‰æ˜¯æ— é™å°æ•°ï¼Œå°†æ‰€æœ‰æ ‡è®°ä¸º INFINITE_DECIMAL
                if is_infinite_decimal:
                    mode = Token.TYPE.INFINITE_DECIMAL

                # æ›´æ–°æ ‡è®°åˆ—è¡¨
                for digit_index in digit_index_range_list:
                    if 0 <= digit_index < len(mark_list):  # ç¡®ä¿ç´¢å¼•åˆæ³•
                        mark_list[digit_index] = mode

        r"""
        é€å­—ç¬¦æ‰«æ
        """
        # é€å­—ç¬¦æ‰«æ
        for index, unit in enumerate(zip(expression, mark_list)):
            unit_char: str = unit[0]
            unit_type = unit[1]

            # å·²ç»æ ‡è®°è¿‡
            if unit_type != Token.TYPE.UNKNOWN:
                continue

            # æ ‡è®°å‡½æ•°å‚æ•°åˆ†éš”ç¬¦
            if unit_char in ",":
                mark_list[index] = Token.TYPE.PARAM_SEPARATOR
                continue

            # æ ‡è®°æ‹¬å·
            if unit_char in "{[(":
                mark_list[index] = Token.TYPE.LBRACKET
                continue
            if unit_char in ")]}":
                mark_list[index] = Token.TYPE.RBRACKET
                continue

            # æ ‡è®°éæ•°å­—
            if unit_char in ["Ï€", "ğ‘’"]:
                mark_list[index] = Token.TYPE.NATIVE_IRRATIONAL
                continue

            if unit_char in symbol_mapping_table.keys():
                mark_list[index] = Token.TYPE.OPERATOR
                continue
            else:
                mark_list[index] = Token.TYPE.SHORT_CUSTOM
                continue

        """
        åˆå¹¶Token
        """
        tokens = []  # æœ€ç»ˆç”Ÿæˆçš„ Token åˆ—è¡¨
        current_type = None  # å½“å‰æ­£åœ¨å¤„ç†çš„ Token ç±»å‹
        current_value = ""  # å½“å‰æ­£åœ¨æ„é€ çš„ Token å€¼
        current_start = 0  # å½“å‰ Token çš„èµ·å§‹ç´¢å¼•

        # éœ€è¦åˆå¹¶çš„ Token ç±»å‹
        mergeable_types = {
            Token.TYPE.PERCENTAGE,
            Token.TYPE.INFINITE_DECIMAL,
            Token.TYPE.FINITE_DECIMAL,
            Token.TYPE.INTEGER,
            Token.TYPE.LONG_CUSTOM,
            Token.TYPE.IRRATIONAL_PARAM,
            Token.TYPE.FUNCTION,
            Token.TYPE.UNKNOWN,
        }

        for i, (char, token_type) in enumerate(zip(expression, mark_list)):
            if current_type is None:  # åˆå§‹åŒ–ç¬¬ä¸€ä¸ª Token
                current_type = token_type
                current_value = char
                current_start = i
            elif token_type == current_type and token_type in mergeable_types:  # å¦‚æœç±»å‹ç›¸åŒä¸”å¯åˆå¹¶ï¼Œç»§ç»­åˆå¹¶
                current_value += char
            else:  # é‡åˆ°ä¸åŒç±»å‹çš„ Tokenï¼Œä¿å­˜å½“å‰ Tokenï¼Œå¹¶å¼€å§‹æ–°çš„ Token
                tokens.append(Token(current_type, current_value, [current_start, i]))
                current_type = token_type
                current_value = char
                current_start = i

        # å¤„ç†æœ€åä¸€ä¸ª Token
        if current_type is not None:
            tokens.append(Token(current_type, current_value, [current_start, len(expression)]))

        return tokens

    @staticmethod
    def update(tokens: list[Token]) -> [list[Token], str]:
        r"""
        æ›´æ–°è¾“å…¥çš„ Token æµ
        :return: ä¸€ä¸ªåˆ—è¡¨, ç¬¬ä¸€é¡¹æ˜¯æ›´æ–°åçš„ Token æµ, ç¬¬äºŒé¡¹æ˜¯è¡¨è¾¾å¼å­—ç¬¦ä¸²
        """
        update_expression = ""
        start_index = 0
        result = []

        for token_index, process_token in enumerate(tokens):
            update_expression += process_token.value

            # è®¡ç®—å½“å‰ token çš„ range
            if token_index == 0:
                process_token.range = [start_index, start_index + len(process_token.value)]
            else:
                previous_token = tokens[token_index - 1]
                if previous_token.range[1] != process_token.range[0]:
                    process_token.range = [start_index, start_index + len(process_token.value)]
                else:
                    process_token.range = [previous_token.range[1], previous_token.range[1] + len(process_token.value)]

            # æ— è®ºå¦‚ä½•éƒ½å°†å½“å‰ token æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            result.append(process_token)
            start_index = process_token.range[1]

        return [result, update_expression]

"""test"""

if __name__ == '__main__':
    import simpsave as ss
    from oloc_preprocessor import Preprocessor

    def run_test():
        tests = ss.read('test_cases', file='./data/oloctest.ini')
        time_costs = []
        print('___________')
        for index, test in enumerate(tests):
            # if target_index % 200 == 0:
            #     print("=", end="")
            try:
                preprocessor = Preprocessor(test)
                preprocessor.execute()
                lexer = Lexer(preprocessor.expression)
                lexer.execute()
                print(test, end=" => ")
                for token in lexer.tokens:
                    print(token.value, end=" ")
                print("")
                time_costs.append(lexer.time_cost)
            except Exception as e:
                print(e)
        print(f"\n"
              f"Avg Time Cost For {len(time_costs)} cases: {sum(time_costs) / len(time_costs) / 1000000} ms\n"
              )


    while True:
        expression = input(">>")
        preprocessor = Preprocessor(expression)
        preprocessor.execute()
        lexer = Lexer(preprocessor.expression)
        lexer.execute()
        print(lexer.tokens)
        print(preprocessor.time_cost + lexer.time_cost)