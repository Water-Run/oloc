r"""
:author: WaterRun
:date: 2025-03-11
:file: lexer.py
:description: Oloc lexer
"""

import utils

from enum import Enum
import re


class Token:
    r"""
    è¡¨è¾¾å¼ä¸­çš„è¯å…ƒ
    :param token_type: è¯å…ƒçš„ç±»åˆ«
    :param token_range: è¯å…ƒåœ¨è¡¨è¾¾å¼ä¸­çš„èŒƒå›´(ä½ç½®)
    :param token_value: è¯å…ƒçš„å®é™…å€¼
    """

    class TYPE(Enum):
        r"""
        æšä¸¾è¯åŸçš„æ‰€æœ‰ç±»å‹
        """
        # æ•°å­—ç±»å‹
        PERCENTAGE = 'percentage'  # ç™¾åˆ†æ•°: 100%
        MIXED_FRACTION = 'mixed fraction'  # å¸¦åˆ†æ•°: 3\1/2
        INFINITE_DECIMAL = 'infinite recurring decimal'  # æ— é™å°æ•°: 3.3... æˆ– 2.3:4
        FINITE_DECIMAL = 'finite decimal'  # æœ‰é™å°æ•°: 3.14
        INTEGER = 'integer'  # æ•´æ•°: 42
        FRACTION = 'fraction'  # åˆ†æ•°: 1/2

        # æ— ç†æ•°ç±»å‹
        NATIVE_IRRATIONAL = 'native irrational number'  # åŸç”Ÿæ— ç†æ•°: Ï€, e
        SHORT_CUSTOM = 'short custom irrational'  # çŸ­è‡ªå®šä¹‰æ— ç†æ•°: x, y
        LONG_CUSTOM = 'long custom irrational'  # é•¿è‡ªå®šä¹‰æ— ç†æ•°: <name>

        # è¿ç®—ç¬¦
        OPERATOR = 'operator'  # è¿ç®—ç¬¦: +, -, *, /ç­‰
        LBRACKET = 'left bracket'  # å·¦æ‹¬å·: (, [, {
        RBRACKET = 'right bracket'  # å³æ‹¬å·: ), ], }

        # å‡½æ•°ç›¸å…³
        FUNCTION = 'function'  # å‡½æ•°: sin, powç­‰
        PARAM_SEPARATOR = 'parameter separator'  # å‚æ•°åˆ†éš”ç¬¦: ,æˆ–;

        # æœªçŸ¥ç±»å‹
        UNKNOWN = 'unknown'  # æ— æ³•è¯†åˆ«çš„å­—ç¬¦

    def __init__(self, token_type: TYPE, token_range: list[int, int], token_value: str = None):
        self.type = token_type
        self.range = token_range
        self.value = token_value if token_value is not None else None
        self.is_legal = False
        self._check_legal()

    def __repr__(self):
        return f"Token({self.type.value}, {self.range}, '{self.value}')"

    def _check_legal(self) -> bool:
        r"""
        æ£€æŸ¥è‡ªèº«çš„åˆæ³•æ€§
        :return: è‡ªèº«æ˜¯å¦æ˜¯ä¸€ä¸ªåˆæ³•çš„Token
        """
        # æ ¹æ®Tokenç±»å‹è°ƒç”¨ç›¸åº”çš„æ£€æŸ¥æ–¹æ³•
        checker_method_name = f"_check_{self.type.name.lower()}"
        if hasattr(self, checker_method_name) and self.value is not None:
            checker_method = getattr(self, checker_method_name)
            self.is_legal = checker_method()
        else:
            self.is_legal = False
        return self.is_legal

    # å„ç§æ£€æŸ¥æ–¹æ³•å®šä¹‰ï¼Œç°åœ¨å®ƒä»¬æ˜¯å®ä¾‹æ–¹æ³•è€Œä¸æ˜¯ç±»æ–¹æ³•
    def _check_integer(self) -> bool:
        r"""
        æ£€æŸ¥æ•´æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return self.value.isdigit()

    def _check_finite_decimal(self) -> bool:
        r"""
        æ£€æŸ¥æœ‰é™å°æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return bool(re.match(r'^\d+\.\d+$', self.value))

    def _check_infinite_decimal(self) -> bool:
        r"""
        æ£€æŸ¥æ— é™å°æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        # æƒ…å†µ1: ä»¥3-6ä¸ªç‚¹ç»“å°¾ï¼Œå¦‚ 3.14...
        if re.search(r'\.\d+\.{3,6}$', self.value):
            base = re.sub(r'\.{3,6}$', '', self.value)
            return bool(re.match(r'^\d+\.\d+$', base))

        # æƒ…å†µ2: ä»¥:åŠ æ•´æ•°ç»“å°¾ï¼Œå¦‚ 2.3:4
        if ':' in self.value:
            match = re.match(r'^(\d+\.\d+):(\d+)$', self.value)
            return bool(match)

        return False

    def _check_fraction(self) -> bool:
        r"""
        æ£€æŸ¥åˆ†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return bool(re.match(r'^\d+/\d+$', self.value))

    def _check_mixed_fraction(self) -> bool:
        r"""
        æ£€æŸ¥å¸¦åˆ†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return bool(re.match(r'^\d+\\\d+/\d+$', self.value))

    def _check_percentage(self) -> bool:
        r"""
        æ£€æŸ¥ç™¾åˆ†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return bool(re.match(r'^\d+(\.\d+)?%$', self.value))

    def _check_native_irrational(self) -> bool:
        r"""
        æ£€æŸ¥åŸç”Ÿæ— ç†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return bool(re.match(r'^[Ï€eğ‘’](\d+\?)?$', self.value))

    def _check_short_custom(self) -> bool:
        r"""
        æ£€æŸ¥è‡ªå®šä¹‰çŸ­æ— ç†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        try:
            from utils import get_symbol_mapping_table

            symbol_mapping_table = get_symbol_mapping_table()

            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå­—ç¬¦æ˜¯å¦æ˜¯è‡ªå®šä¹‰çŸ­æ— ç†æ•°ï¼ˆä¸åœ¨æ˜ å°„è¡¨çš„é”®ä¸­ï¼‰
            if len(self.value) < 1 or self.value[0] in symbol_mapping_table.keys():
                return False

            # å¦‚æœåªæœ‰ä¸€ä¸ªå­—ç¬¦ï¼Œæ˜¯åˆæ³•çš„
            if len(self.value) == 1:
                return True

            # æ£€æŸ¥ç»“å°¾æ˜¯å¦æœ‰?
            if self.value.endswith('?'):
                # å»æ‰ç¬¬ä¸€ä¸ªå­—ç¬¦å’Œ?åæ£€æŸ¥å‰©ä½™éƒ¨åˆ†
                remaining = self.value[1:-1]

                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥å‰©ä½™éƒ¨åˆ†
                return bool(re.match(r'^[+-]$|^[+-]?\d+(\.\d+)?$', remaining))

            # å¦åˆ™ä¸åˆæ³•
            return False
        except ImportError:
            # å¤„ç†utilsæ¨¡å—å¯¼å…¥å¤±è´¥çš„æƒ…å†µ
            return False

    def _check_long_custom(self) -> bool:
        r"""
        æ£€æŸ¥è‡ªå®šä¹‰é•¿æ— ç†æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥é•¿è‡ªå®šä¹‰æ— ç†æ•°æ ¼å¼
        base_match = re.match(r'^<([^<>]+)>([+-]|\d+(\.\d+)?|[+-]\d+(\.\d+)?)?\?$', self.value)
        if base_match:
            return True

        # ç®€å•æ ¼å¼ <name>
        return bool(re.match(r'^<[^<>]+>$', self.value))

    def _check_operator(self) -> bool:
        r"""
        æ£€æŸ¥è¿ç®—ç¬¦ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        try:
            from utils import get_symbol_mapping_table

            symbol_mapping_table = get_symbol_mapping_table()
            # æ’é™¤åˆ†ç»„è¿ç®—ç¬¦
            brackets = ['(', ')', '[', ']', '{', '}']

            # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ˜ å°„è¡¨ä¸­ä¸”ä¸æ˜¯æ‹¬å·
            return self.value in symbol_mapping_table.keys() and self.value not in brackets
        except ImportError:
            # å¤„ç†utilsæ¨¡å—å¯¼å…¥å¤±è´¥çš„æƒ…å†µ
            return False

    def _check_lbracket(self) -> bool:
        r"""
        æ£€æŸ¥å·¦æ‹¬å·ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return self.value in ['(', '[', '{']

    def _check_rbracket(self) -> bool:
        r"""
        æ£€æŸ¥å³æ‹¬å·ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return self.value in [')', ']', '}']

    def _check_param_separator(self) -> bool:
        r"""
        æ£€æŸ¥å‚æ•°åˆ†éš”ç¬¦ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        return self.value in [',', ';']

    def _check_function(self) -> bool:
        r"""
        æ£€æŸ¥å‡½æ•°ç±»å‹çš„Tokençš„åˆæ³•æ€§
        :return: æ˜¯å¦åˆæ³•
        """
        try:
            from utils import get_function_name_list

            function_list = get_function_name_list()
            return self.value in function_list
        except ImportError:
            # å¤„ç†utilsæ¨¡å—å¯¼å…¥å¤±è´¥çš„æƒ…å†µ
            return False


class Lexer:
    r"""
    è¯æ³•åˆ†æå™¨
    :param expression: å¾…å¤„ç†çš„è¡¨è¾¾å¼
    """

    def __init__(self, expression: str):
        self.expression = expression

    def execute(self):
        ...

    @staticmethod
    def _is_native_irrational(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºåŸç”Ÿæ— ç†æ•°
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯åŸç”Ÿæ— ç†æ•°(Ï€æˆ–e)åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return to_check in ["Ï€", "ğ‘’"]

    @staticmethod
    def _is_operator(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºè¿ç®—ç¬¦
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯è¿ç®—ç¬¦åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        operators = list(utils.get_symbol_mapping_table().keys())
        operators = [op for op in operators if op and op not in "()[]{}<>"]  # ä¸åŒ…å«åˆ†ç»„è¿ç®—ç¬¦
        return to_check in operators

    @staticmethod
    def _is_bracket(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºæ‹¬å·
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯æ‹¬å·åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return to_check in "()[]{}"

    @staticmethod
    def _is_separator(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºå‡½æ•°å‚æ•°åˆ†éš”ç¬¦(é¢„å¤„ç†é˜¶æ®µå·²æ¶ˆé™¤æ•°å­—åˆ†éš”ç¬¦)
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯å‡½æ•°å‚æ•°åˆ†éš”ç¬¦åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return to_check in ",;"

    @staticmethod
    def _is_digit(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºæ•°å­—å­—ç¬¦
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯æ•°å­—æˆ–å°æ•°ç‚¹åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return to_check.isdigit() or to_check == '.'

    @staticmethod
    def _is_identifier_char(to_check: str) -> bool:
        r"""
        åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡è¯†ç¬¦å­—ç¬¦
        :param to_check: å¾…æ£€æŸ¥çš„å­—ç¬¦
        :return: å¦‚æœæ˜¯æ ‡è¯†ç¬¦å­—ç¬¦(å­—æ¯ã€æ•°å­—æˆ–ä¸‹åˆ’çº¿)åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return to_check.isalnum() or to_check == '_'

    @staticmethod
    def tokenizer(expression: str) -> list[Token]:
        r"""
        åˆ†è¯å™¨
        :param expression: å¾…åˆ†è¯çš„è¡¨è¾¾å¼
        :return: åˆ†è¯åçš„Tokenåˆ—è¡¨
        """
        tokens = []
        i = 0
        function_names = utils.get_function_name_list()

        while i < len(expression):
            # è·³è¿‡ç©ºç™½å­—ç¬¦
            if expression[i].isspace():
                i += 1
                continue

            # å¤„ç†æ•°å­—(æ•´æ•°ã€å°æ•°ã€åˆ†æ•°ã€ç™¾åˆ†æ•°ç­‰)
            if expression[i].isdigit() or (
                    expression[i] == '.' and i + 1 < len(expression) and expression[i + 1].isdigit()):
                start = i
                decimal_point = False
                percentage = False
                fraction = False
                mixed_fraction = False
                infinite = False

                # å¤„ç†æ•°å­—éƒ¨åˆ†
                while i < len(expression):
                    # æ•´æ•°éƒ¨åˆ†
                    if expression[i].isdigit():
                        i += 1
                    # å¤„ç†å°æ•°ç‚¹
                    elif expression[i] == '.' and not decimal_point:
                        decimal_point = True
                        i += 1
                    # å¤„ç†åˆ†æ•°
                    elif expression[i] == '/' and not fraction:
                        # ç¡®ä¿å‰é¢æœ‰æ•°å­—
                        if i > start:
                            fraction = True
                            i += 1
                        else:
                            break
                    # å¤„ç†å¸¦åˆ†æ•°
                    elif expression[i] == '\\' and not mixed_fraction:
                        # ç¡®ä¿å‰é¢æœ‰æ•°å­—ï¼Œåé¢æœ‰åˆ†æ•°
                        if i > start and i + 1 < len(expression) and (
                                expression[i + 1].isdigit() or expression[i + 1] == '-'):
                            mixed_fraction = True
                            i += 1
                        else:
                            break
                    # å¤„ç†æ˜¾å¼å¾ªç¯å°æ•°éƒ¨åˆ†
                    elif expression[i] == ':' and decimal_point:
                        infinite = True
                        i += 1
                        # è·³è¿‡å†’å·åçš„æ•°å­—ï¼Œå®ƒä»¬æ˜¯å¾ªç¯éƒ¨åˆ†
                        while i < len(expression) and expression[i].isdigit():
                            i += 1
                        break
                    # å¤„ç†çœç•¥å·(æ— é™å¾ªç¯å°æ•°)
                    elif expression[i] == '.' and decimal_point:
                        # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘3ä¸ªè¿ç»­çš„ç‚¹
                        j = i
                        dot_count = 0
                        while j < len(expression) and expression[j] == '.':
                            dot_count += 1
                            j += 1

                        if dot_count >= 3:
                            infinite = True
                            i = j  # è·³è¿‡æ‰€æœ‰ç‚¹
                            break
                        else:
                            break
                    # å¤„ç†ç™¾åˆ†æ•°
                    elif expression[i] == '%':
                        # æ£€æŸ¥åé¢ä¸æ˜¯æ•°å­—æˆ–æ‹¬å·ï¼Œç¡®ä¿è¿™ä¸æ˜¯æ¨¡è¿ç®—ç¬¦
                        if i + 1 >= len(expression) or (
                                not expression[i + 1].isdigit() and expression[i + 1] not in "([{"):
                            percentage = True
                            i += 1
                        break
                    else:
                        break

                # æ ¹æ®è¯†åˆ«çš„ç‰¹å¾ç¡®å®šæ•°å­—ç±»å‹
                token_value = expression[start:i]

                if percentage:
                    token_type = Token.TYPE.PERCENTAGE
                elif mixed_fraction:
                    token_type = Token.TYPE.MIXED_FRACTION
                elif infinite:
                    token_type = Token.TYPE.INFINITE_DECIMAL
                elif decimal_point:
                    token_type = Token.TYPE.FINITE_DECIMAL
                elif fraction:
                    token_type = Token.TYPE.FRACTION
                else:
                    token_type = Token.TYPE.INTEGER

                tokens.append(Token(token_type, [start, i], token_value))
                continue

            # å¤„ç†åŸç”Ÿæ— ç†æ•°(Ï€, e)
            if Lexer._is_native_irrational(expression[i]):
                start = i
                i += 1

                # æ£€æŸ¥æ— ç†æ•°åçš„å¯é€‰é—®å·è¡¨è¾¾å¼
                if i < len(expression) and expression[i] == '?':
                    i += 1
                    # å¯»æ‰¾é—®å·åçš„æ•´æ•°(ä¿ç•™ä½æ•°)
                    while i < len(expression) and expression[i].isdigit():
                        i += 1

                tokens.append(Token(Token.TYPE.NATIVE_IRRATIONAL, [start, i], expression[start:i]))
                continue

            # å¤„ç†è‡ªå®šä¹‰é•¿æ— ç†æ•° <name>
            if expression[i] == '<':
                start = i
                i += 1
                # æŸ¥æ‰¾å³å°–æ‹¬å·
                while i < len(expression) and expression[i] != '>':
                    i += 1

                if i < len(expression) and expression[i] == '>':
                    i += 1

                    # æ£€æŸ¥æ— ç†æ•°åçš„å¯é€‰é—®å·è¡¨è¾¾å¼
                    if i < len(expression) and expression[i] == '?':
                        i += 1
                        # å¤„ç†é—®å·åçš„å€¼æˆ–ç¬¦å·
                        if i < len(expression) and (expression[i] == '+' or expression[i] == '-'):
                            i += 1
                        else:
                            # å¤„ç†å°æ•°
                            decimal_seen = False
                            while i < len(expression) and (
                                    expression[i].isdigit() or (expression[i] == '.' and not decimal_seen)):
                                if expression[i] == '.':
                                    decimal_seen = True
                                i += 1

                    tokens.append(Token(Token.TYPE.LONG_CUSTOM, [start, i], expression[start:i]))
                    continue

            # å¤„ç†å‡½æ•°
            potential_func = ""
            j = i
            while j < len(expression) and Lexer._is_identifier_char(expression[j]):
                potential_func += expression[j]
                j += 1

            if potential_func in function_names and j < len(expression) and expression[j] == '(':
                start = i
                i = j + 1  # è·³è¿‡å·¦æ‹¬å·
                tokens.append(Token(Token.TYPE.FUNC, [start, j], potential_func))
                tokens.append(Token(Token.TYPE.LBRACKET, [j, j + 1], '('))
                continue

            # å¤„ç†è‡ªå®šä¹‰çŸ­æ— ç†æ•°(å•ä¸ªå­—ç¬¦)
            if expression[i].isalpha() and not Lexer._is_native_irrational(expression[i]):
                start = i
                i += 1

                # æ£€æŸ¥æ— ç†æ•°åçš„å¯é€‰é—®å·è¡¨è¾¾å¼
                if i < len(expression) and expression[i] == '?':
                    i += 1
                    if i < len(expression):
                        if expression[i] in '+-':
                            i += 1
                        else:
                            # å¤„ç†å°æ•°å€¼
                            decimal_seen = False
                            while i < len(expression) and (
                                    expression[i].isdigit() or (expression[i] == '.' and not decimal_seen)):
                                if expression[i] == '.':
                                    decimal_seen = True
                                i += 1

                tokens.append(Token(Token.TYPE.SHORT_CUSTOM, [start, i], expression[start:i]))
                continue

            # å¤„ç†è¿ç®—ç¬¦
            if Lexer._is_operator(expression[i]):
                start = i

                # ç‰¹æ®Šå¤„ç†å¯èƒ½çš„å¤šå­—ç¬¦è¿ç®—ç¬¦
                if expression[i] == '*' and i + 1 < len(expression) and expression[i + 1] == '*':
                    # å¤„ç† ** è¿ç®—ç¬¦
                    tokens.append(Token(Token.TYPE.OPERATOR, [i, i + 2], '**'))
                    i += 2
                elif expression[i] == '%':
                    # ç®€å•å¤„ç†%ç¬¦å·ï¼Œåç»­å‡½æ•°åŒ–æµç¨‹ä¼šåŒºåˆ†ç™¾åˆ†æ¯”å’Œå–ä½™
                    tokens.append(Token(Token.TYPE.OPERATOR, [i, i + 1], '%'))
                    i += 1
                else:
                    # å…¶ä»–å•å­—ç¬¦è¿ç®—ç¬¦
                    tokens.append(Token(Token.TYPE.OPERATOR, [i, i + 1], expression[i]))
                    i += 1
                continue

            # å¤„ç†æ‹¬å·
            if Lexer._is_bracket(expression[i]):
                start = i
                if expression[i] in '([{':
                    tokens.append(Token(Token.TYPE.LBRACKET, [i, i + 1], expression[i]))
                else:
                    tokens.append(Token(Token.TYPE.RBRACKET, [i, i + 1], expression[i]))
                i += 1
                continue

            # å¤„ç†å‡½æ•°å‚æ•°åˆ†éš”ç¬¦
            if Lexer._is_separator(expression[i]):
                tokens.append(Token(Token.TYPE.PARAM_SEPARATOR, [i, i + 1], expression[i]))
                i += 1
                continue

            # æ— æ³•è¯†åˆ«çš„å­—ç¬¦ï¼Œå½’ç±»ä¸ºUNKNOWN
            start = i
            tokens.append(Token(Token.TYPE.UNKNOWN, [i, i + 1], expression[i]))
            i += 1

        return tokens


"""test"""
if __name__ == '__main__':
    test_list = [
        # åŸºç¡€æ•´æ•°æµ‹è¯•
        "42",
        "-42",
        "+42",
        "0",

        # å°æ•°æµ‹è¯•
        "3.14",
        "-3.14",
        "0.5",
        ".5",  # çœç•¥æ•´æ•°éƒ¨åˆ†çš„å°æ•°
        "10.",  # çœç•¥å°æ•°éƒ¨åˆ†çš„å°æ•°

        # ç™¾åˆ†æ•°æµ‹è¯•
        "50%",
        "-25%",
        "3.14%",
        "0%",

        # åˆ†æ•°æµ‹è¯•
        "1/2",
        "-1/2",
        "7/8",
        "0/1",
        "5/-10",  # åˆ†æ¯ä¸ºè´Ÿ
        "22/7",  # Ï€çš„è¿‘ä¼¼å€¼

        # å¸¦åˆ†æ•°æµ‹è¯•
        "3\\1/2",  # 3+1/2 = 7/2
        "-2\\1/4",
        "10\\3/4",
        "0\\1/2",

        # æ— é™å¾ªç¯å°æ•°æµ‹è¯•
        "0.333...",
        "1.414...",
        "0.9999...",
        "0.123...",
        "0.142857142857...",  # 1/7çš„å¾ªç¯å°æ•°

        # æ˜¾å¼å¾ªç¯å°æ•°æµ‹è¯•
        "0.3:3",  # 0.333...
        "1.4:14",  # 1.414141...
        "0.:9",  # 0.999...
        "0.1:42857",  # 1/7 = 0.142857142857...

        # åŸç”Ÿæ— ç†æ•°æµ‹è¯•
        "Ï€",
        "ğ‘’",
        "Ï€?3",  # å¸¦ç²¾åº¦æŒ‡ç¤ºçš„Ï€
        "ğ‘’?5",  # å¸¦ç²¾åº¦æŒ‡ç¤ºçš„e

        # çŸ­è‡ªå®šä¹‰æ— ç†æ•°æµ‹è¯•
        "x",
        "y",
        "a",
        "z",
        "x?-",  # è´Ÿæ•°è‡ªå®šä¹‰æ— ç†æ•°
        "y?+",  # æ­£æ•°è‡ªå®šä¹‰æ— ç†æ•°
        "a?2.5",  # å¸¦å€¼çš„è‡ªå®šä¹‰æ— ç†æ•°

        # é•¿è‡ªå®šä¹‰æ— ç†æ•°æµ‹è¯•
        "<phi>",
        "<é»„é‡‘åˆ†å‰²æ¯”>",
        "<root2>",
        "<Pi approximation>",
        "<phi>?1.618",  # å¸¦å€¼çš„é•¿è‡ªå®šä¹‰æ— ç†æ•°
        "<negative>?-",  # è´Ÿæ•°é•¿è‡ªå®šä¹‰æ— ç†æ•°
        "<positive>?+",  # æ­£æ•°é•¿è‡ªå®šä¹‰æ— ç†æ•°

        # è¿ç®—ç¬¦æµ‹è¯•
        "1+2",
        "3-4",
        "5*6",
        "7/8",
        "2^3",
        "2**3",  # å¹‚è¿ç®—ç¬¦çš„å¦ä¸€ç§è¡¨ç¤º
        "10%3",  # å–ä½™è¿ç®—ç¬¦
        "5!",  # é˜¶ä¹˜
        "90Â°",  # è§’åº¦ç¬¦å·
        "|x|",  # ç»å¯¹å€¼
        "âˆš16",  # å¹³æ–¹æ ¹

        # æ‹¬å·æµ‹è¯•
        "(1+2)",
        "[3*4]",
        "{5/6}",
        "((1+2)*(3-4))",
        "[(1+2)*(3+4)]",
        "{(1+2)*[3+4]}",

        # å‡½æ•°æµ‹è¯•
        "sin(Ï€/2)",
        "cos(0)",
        "tan(Ï€/4)",
        "sqrt(16)",
        "log(100)",
        "ln(ğ‘’)",
        "pow(2,3)",
        "abs(-5)",
        "gcd(12,18)",
        "lcm(4,6)",

        # å‡½æ•°å‚æ•°åˆ†éš”ç¬¦æµ‹è¯•
        "pow(2,3)",
        "pow(2;3)",  # ä½¿ç”¨åˆ†å·ä½œä¸ºå‚æ•°åˆ†éš”ç¬¦
        "gcd(12,18)",
        "gcd(12;18)",
        "max(1,2,3,4)",
        "max(1;2;3;4)",

        # å¤æ‚è¡¨è¾¾å¼æµ‹è¯•
        "1+2*3",
        "(1+2)*3",
        "3*(4+5)/2",
        "sin(Ï€/2)*cos(Ï€/3)",
        "sqrt(2)^2",
        "âˆš(4+5)*(2-1)",
        "2Ï€*r",  # åœ†å‘¨é•¿å…¬å¼
        "Ï€*r^2",  # åœ†é¢ç§¯å…¬å¼
        "3\\1/2 + 2\\3/4",  # å¸¦åˆ†æ•°åŠ æ³•
        "sin(2Ï€/3)?3 + cos(Ï€/4)?4",  # å¸¦ç²¾åº¦æŒ‡ç¤ºçš„å‡½æ•°

        # æ··åˆè¡¨è¾¾å¼æµ‹è¯•
        "3+4*2/(1-5)^2",
        "3+4*2/(1-5)^2^3",
        "sin(Ï€/2) + cos(Ï€/3) + tan(Ï€/4)",
        "(2.5+1.5)*(3.75-0.75)/(2.25+0.75)",
        "âˆš(a^2+b^2)",  # å‹¾è‚¡å®šç†
        "2Ï€r + 2Ï€h",  # åœ†æŸ±è¡¨é¢ç§¯
        "a*sin(Î±) + b*cos(Î²)",

        # é”™è¯¯å¤„ç†æµ‹è¯•
        "2++3",  # è¿ç»­å¤šä¸ªåŠ å·
        "4-*5",  # ç›¸è¿çš„ä¸å…¼å®¹è¿ç®—ç¬¦
        "6(/7",  # ä¸åŒ¹é…çš„æ‹¬å·
        "8)",  # ç¼ºå°‘å·¦æ‹¬å·
        "sin()",  # ç¼ºå°‘å‡½æ•°å‚æ•°
        "log(,)",  # åˆ†éš”ç¬¦æ— å‚æ•°
        "3,4,5",  # ä¸Šä¸‹æ–‡å¤–çš„åˆ†éš”ç¬¦

        # æ˜“é”™æƒ…å†µæµ‹è¯•
        "2(3+4)",  # éšå¼ä¹˜æ³•
        "2Ï€",  # æ•°å­—ä¸æ— ç†æ•°ç›¸ä¹˜
        "sin(Ï€)cos(0)",  # å‡½æ•°è¿ä¹˜
        "3.14.15",  # å¤šä¸ªå°æ•°ç‚¹
        "5/6/7",  # è¿ç»­åˆ†æ•°
        "2//3",  # è¿ç»­é™¤å·
        "3%",  # ç™¾åˆ†å·è€Œéå–ä½™
        "5%2",  # å–ä½™è€Œéç™¾åˆ†å·
        "x?-1.5",  # è´Ÿæ•°å€¼çš„æ— ç†æ•°

        # æç«¯æƒ…å†µæµ‹è¯•
        "",  # ç©ºå­—ç¬¦ä¸²
        " ",  # åªæœ‰ç©ºæ ¼
        "1000000000",  # å¤§æ•´æ•°
        "0.000000001",  # å°å°æ•°
        "1/1000000000",  # å°åˆ†æ•°
        "999999999/1",  # å¤§åˆ†æ•°
        "999\\999/999",  # å¤§å¸¦åˆ†æ•°
        ".5.5.5.5.5.5",  # å¤šé‡é‡å¤

        # æ— ç†æ•°ç»“åˆæµ‹è¯•
        "Ï€+ğ‘’",
        "Ï€*ğ‘’",
        "Ï€/ğ‘’",
        "Ï€^ğ‘’",
        "âˆšÏ€",
        "log(ğ‘’)",
        "sin(Ï€+ğ‘’)",

        # å¤åˆè¡¨è¾¾å¼æµ‹è¯•
        "3*(4+5)^2/sin(Ï€/3)",
        "log10(1000)/(2Ï€*âˆš(LC))",
        "(a+b)^2 = a^2 + 2ab + b^2",
        "F = G*m1*m2/r^2",  # ä¸‡æœ‰å¼•åŠ›å…¬å¼
        "E = mc^2",  # è´¨èƒ½æ–¹ç¨‹
        "PV = nRT",  # ç†æƒ³æ°”ä½“çŠ¶æ€æ–¹ç¨‹
    ]
    for test in test_list:
        try:
            print(f"Testing: {test}")
            from preprocessor import Preprocessor

            test_result = Preprocessor(test)
            test_result.execute()
            tokens = Lexer.tokenizer(test_result.expression)
            for token in tokens:
                if not token.is_legal:
                    print(token)
        except Exception as error:
            print(error)
    while True:
        try:
            test_result = Preprocessor(input(">>"))
            test_result.execute()
            tokens = Lexer.tokenizer(test_result.expression)
            for token in tokens:
                print(f"  {token}")
        except Exception as error:
            print(error)
