# 词法分析器  

预处理器是`oloc`在执行运算时的第二个子程序,负责将输入的表达式进行分词,并执行静态检查.  
词法分析器位于`lexer.py`.  
词法分析器实例于`Lexer`类.  

## 关于`Token`  

类`Token`是词法分析的一个基本单元,也是之后处理的基本单元.    
`Token`的类别是其的子枚举`TYPE`.`Token`被分类为以下类别:  
1. 有理数类型  
    - 整数型: `INTEGER`  
    - 有限小数型: `FINITE_DECIMAL`  
    - 无限循环小数型: `INFINITE_DECIMAL`
    - 百分数型:`PERCENTAGE`  
    - 带分数型:`MIXED_FRACTION`  
2. 无理数类型  
    - 原生无理数: `NATIVE_IRRATIONAL`  
    - 短自定义无理数: `SHORT_CUSTOM`  
    - 长自定义无理数: `LONG_CUSTOM`  
    - 无理数参数: `IRRATIONAL_PARAM`  
3. 运算符型  
    - 非分组运算符: `OPERATOR`  
    - 左括号: `LBRACKET`  
    - 右括号: `RBRACKET`  
4. 函数相关  
    - 函数: `FUNCTION`  
    - 函数分隔符: `PARAM_SEPARATOR`  
5. 未知  
    - 未知(异常时): `UNKNOWN`  
   
分数作为整数+运算符(`/`)+整数看待.  

> 关于类别的详细内容, 见[数字](../../使用教程/数字.md),[运算符](../../使用教程/运算符.md)和[函数](../../使用教程/函数.md)  

`Token`具备如下属性:  

- `type`:`TYPE` `Token`的类型  
- `range`:`list[int, int]` `Token`在(构造它的)表达式中的范围(`[前下标,后下标]`)  
- `value`:`str` `Token`的值,及其对应的具体子表达式  
- `is_legal`:`bool` 该`Token`是否合法.在`Token`实例化时,会自动进行检测  

## 公有的静态方法  

词法分析器提供了以下公有的的静态方法.  

> 将这些方法设计为公有的静态方法主要是为了未来的兼容性考虑  

### `Lexer`中的静态方法  

`Lexer`中的通用的`Token`处理(及表达式生成)相关的内容作为静态方法.   

- `tokenizer`  
    - **说明**  
        - 对输入的字符串表达式进行分词,转换为`Token`列表  
    - **参数**  
        - `expression`:`str` 执行分词的表达式    
    - **实现**  
        - 生成一个逐字符标注列表  
        - 扫描表达式中成模块部分
          - 标注自定义长无理数
              - 检测`<` `>`部分
          - 标注无理数参数  
              - 检测`?`  
              - `?`向前,直到遇到非数字,第二个`.`,第二个`+`,第二个`-`    
          - 标注函数名称部分
          - 标注数字部分  
        - 逐字符对表达式进行扫描  
          - 如果遇到`;`或`,`,标记为函数参数分隔符   
          - 如果遇到括号,标记为对应括号  
          - 如果遇到非数字    
              - 如果遇到`π`和`𝑒`,标记为原生无理数   
              - 如果遇到符号映射表中的运算符(关系运算符已在上一步中标记),标记为运算符  
              - 如果遇到非符号映射表中的符号,标记为短自定义无理数
        - 将标注列表转换为Token流  
    - **返回值**  
        - 分词后的Token流:`list[Token]`  


## 输入输出  

词法分析器接受一个参数.  

- `expression`:`str` 输入的表达式  

词法分析器的返回值为`list[Token]`,即分词后的Token列表.其中,类`Token`包含以下属性:  

- `token_type`:`TYPE` Token的类别.其中,`TYPE`是`Token`内置的一个字符串枚举  
- `token_range`:`list[int, int]` Token在表达式中的位置.整数列表的第一个参数是开始的下标,第二个则是结束的下标  
- `value`:`str | None` Token的值(即表达式中的原文)  

## 工作流  

词法分析器按顺序依次执行如下内容.  

1. ***Token流生成与合法性检查***  
   - **功能**  
      - 根据表达式,生成Token流,并检查生成各个Token的合法性      
   - **实现**  
      - 调用`tokenizer`获取分词后的Token流    
      - 扫描对应的结构是否合法    
   - **示例**  
      - *输入*: `1+2+3/4`  
      - *输出*: `["1", "+", "2", "+", "3", "+", "+", "4"]` (以`Token`的`value`属性表示)
   - **异常**  
      - `OlocCommentException`: 当`#`不匹配时  
2. ***形式消除补全***  
    - **功能**  
      - 消除表达式中的一些特殊形式.包括数字分隔符,括号化简,正负号消除,并补全一些特殊形式.如被省略的乘法符号  
    - **实现**  
      - 正负号约除  
        - 检测Token流中中存在的连续的`+`和`-`  
        - 按照正负号消除原则进行消除  
      - 数字分隔符消除  
        - 检查Token流中`,`是否合法   
        - 判断是否是数字分隔符,如果是,移除表达式中的`,`  
      - 乘法符号补全
        - 检查Token流中被省略乘号(且非保护位)的位置  
        - 补全乘号  
    - **示例**  
      - *输入*: `["3,00,00", "+", "+", "-", "-", "x", "pow", "(", "1,100", ";", "1/2", ")"]`  
      - *输出*: `["30000", "+", "x", "*", "pow", "(", "1100", ",", "1/2", ")"]`  
    - **异常**  
      - `OlocNumberSeparatorException`: 当数字分隔符位于非法位置时.如不位于数字的数字分隔符,或如位于数字开头或结尾的分隔符,或连续的`,`分隔符
3. ***分数化***  
   - **功能**  
      - 将表达式中的所有有理数转换为分数  
   - **实现**  
      - 词法分析器扫描标注数字结构
      - 取出词法分析器扫描出的数字结构,并判断合法性  
      - 数字分数化
        - 带分数分数化  
            - 带分数解析为分数  
        - 有限小数分数化  
            - 有限小数解析为分数  
        - 无限循环小数分数化  
            - 无限循环小数解析并分数化  
        - 百分数分数化  
            - 百分小数解析为有限小数,在以下步骤统一进行分数化  
        - 分数化简
            - 对于可化简单元,调用求值器中的分数化简器执行字符串分数化简  
        - 重新生成Token流  
   - **示例**  
      - *输入*: `pow(1,0000;1/2)+100%+50\1/2+0.5+2.222...`  
      - *输出*: `pow(10000;1/2)+1+101/2+1/2+20/9`  
4. ***函数转换***
在此步骤后,Token流中应当只有  
